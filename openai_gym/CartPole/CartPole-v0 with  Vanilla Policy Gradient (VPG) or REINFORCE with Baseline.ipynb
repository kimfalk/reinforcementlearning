{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving CartPole-v0 with the Vanilla Policy Gradient algorithm\n",
    "\n",
    "The following is an implementation of the  Vanilla Policy Gradient (VPG) also known as REINFORCE with baseline. \n",
    "\n",
    "REINFORCE was improved to use a baseline to avoid the large variance due to the Monte carlo targets. \n",
    "\n",
    "```The accumulation of random events along a trajectory, including the initial state sampled from the initial state distribution, transition function probabilities, but now in this chapter with stochastic policies, the randomness action selection adds to the mix. All this randomness is compounded inside the return, making it a high-variance signal challenging to interpret.``` [__Grokking Deep Reinforcement learning__](https://livebook.manning.com/book/grokking-deep-reinforcement-learning/chapter-11/v-14/point-8971-43-43-0)\n",
    "\n",
    "To get around this we will look at how big an advantage an action has over the others. To do this we will need a value function, that estimates the value of the current state. The advantage can then be calculated as the actual return - the value of the state. Using the advantage will create feedback which is more or less centered around zero, and it therefore better to train your agent. \n",
    "\n",
    "The environment Cartpole-v0 is used to test the algorithm, was created by OpenAi and is described in more detail here [cartpolev0]() and here [doc]().\n",
    "\n",
    "If the algorithm manages to execute the simulation of the cartpole for a 100 episodes, keeping it balanced for more then 195 steps the environment is said to be solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_step(state, reward, done, info):\n",
    "    print(f\"state: {state},\\nreward: {reward},\\ndone: {done},\\ninfo: {info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick look at the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [ 0.00625815  0.23923074  0.02483072 -0.31445976],\n",
      "reward: 1.0,\n",
      "done: False,\n",
      "info: {}\n"
     ]
    }
   ],
   "source": [
    "initial_state = env.reset()\n",
    "action = env.action_space.sample()\n",
    "state, reward, done, info = env.step(action)\n",
    "print_step(state, reward, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(x, N=50):\n",
    "    kernel = np.ones(N)\n",
    "    conv_len = x.shape[0]-N\n",
    "    y = np.zeros(conv_len)\n",
    "    for i in range(conv_len):\n",
    "        y[i] = kernel @ x[i:i+N]\n",
    "        y[i] /= N\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network approximating the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "        Fully-Connected Descrete-Action Policy network\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_dim=4, \n",
    "                 hidden_dim=[32, 32], \n",
    "                 output_dim=2):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim[0])\n",
    "        \n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_dim) - 1):\n",
    "            hidden_layer = nn.Linear(hidden_dim[i], hidden_dim[i+1])\n",
    "            self.hidden_layers.append(hidden_layer)\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim[-1], output_dim)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        \n",
    "        x = state\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, \n",
    "                             dtype=torch.float32)\n",
    "            x = x.unsqueeze(0)\n",
    "        \n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for hidden in self.hidden_layers:\n",
    "            x = F.leaky_relu(hidden(x))\n",
    "        \n",
    "        return self.output_layer(x)\n",
    "    \n",
    "    def full_forward_pass(self, state):\n",
    "        \"\"\"\n",
    "            Given a state return:\n",
    "            * action - what action is best to take. \n",
    "            * is_exploritory - was the action different from the greedy one\n",
    "            * logpa - the probability distribution of the actions. \n",
    "            * entropy - how uniform is the probilities. \n",
    "        \"\"\"\n",
    "        \n",
    "        # run the state through the network\n",
    "        logits = self.forward(state) \n",
    "        \n",
    "        # create a probability distribution\n",
    "        dist = torch.distributions.Categorical(logits=logits) \n",
    "        \n",
    "        # sample an action from the distribution\n",
    "        action = dist.sample()\n",
    "        \n",
    "        # what was the log probability of the action  \n",
    "        logpa = dist.log_prob(action).unsqueeze(-1)\n",
    "        \n",
    "        # entropy of the distribution.\n",
    "        entropy = dist.entropy().unsqueeze(-1)\n",
    "        \n",
    "        # did we sample the greedy action?\n",
    "        is_explortionary = action != np.argmax(logits.detach().numpy())\n",
    "        \n",
    "        return action.item(), is_explortionary.item(), logpa, entropy\n",
    "                \n",
    "policy_model = PolicyNetwork()\n",
    "learning_rate = 0.009\n",
    "policy_optimizer = torch.optim.Adam(policy_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network which approximates the state value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateValueNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_dim=4,\n",
    "                 hidden_dim=[32, 32],\n",
    "                 output_dim=1):\n",
    "        super(StateValueNetwork, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim[0])\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_dim) - 1):\n",
    "            hidden_layer = nn.Linear(hidden_dim[i], hidden_dim[i+1])\n",
    "            self.hidden_layers.append(hidden_layer)\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim[-1], output_dim)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        \n",
    "        x = state\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, \n",
    "                             dtype=torch.float32)\n",
    "            x = x.unsqueeze(0)\n",
    "            \n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for hidden in self.hidden_layers:\n",
    "            x = F.leaky_relu(hidden(x))\n",
    "        \n",
    "        return self.output_layer(x)\n",
    "    \n",
    "V = StateValueNetwork()\n",
    "value_optimizer = torch.optim.Adam(V.parameters(), lr=learning_rate)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical(logits: torch.Size([2]))\n",
      "0\n",
      "pred:  Categorical(probs: torch.Size([2]), logits: torch.Size([2]))\n",
      "state: [ 0.00926817 -0.15603818 -0.03036579  0.24913162],\n",
      "reward: 1.0,\n",
      "done: False,\n",
      "info: {}\n"
     ]
    }
   ],
   "source": [
    "initial_state = env.reset()\n",
    "pred = policy_model(torch.from_numpy(initial_state).float())\n",
    "dist = torch.distributions.Categorical(logits=pred) \n",
    "print(dist)\n",
    "action = np.random.choice(np.array([0,1]), p=dist.probs.detach().numpy())\n",
    "print(action)\n",
    "state, reward, done, info = env.step(action)\n",
    "print(\"pred: \",dist)\n",
    "print_step(state, reward, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.880997, 4.9303  , 3.97    , 3.      ]),\n",
       " array([1.      , 0.99    , 0.9801  , 0.970299]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def discount_rewards(rewards, gamma=.99):\n",
    "    \"\"\" reduces the rewards by a discount, here by gamma.\"\"\"\n",
    "    \n",
    "    T = len(rewards)\n",
    "    discounts = np.logspace(0, T, num=T, base=gamma, endpoint=False)\n",
    "    returns = np.array([np.sum(discounts[:T-t] * rewards[t:]) for t in range(T)])\n",
    "\n",
    "    return returns, discounts\n",
    "\n",
    "discount_rewards([1,1,1,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vpg():\n",
    "    \n",
    "    def __init__(self,\n",
    "                policy, \n",
    "                state_value,\n",
    "                policy_optimizer,\n",
    "                value_optimizer,\n",
    "                beta=0.001 # entropy loss weight\n",
    "                ):\n",
    "        self.policy_model = policy\n",
    "        self.state_value_model = state_value\n",
    "        self.beta = beta\n",
    "        self.experiences = []\n",
    "        self.entropies = []\n",
    "        self.episode_exploration = []\n",
    "        self.logpa = []\n",
    "        self.values = []\n",
    "        self.actions_taken = {}\n",
    "        self.policy_optimizer = policy_optimizer\n",
    "        self.value_optimizer= value_optimizer\n",
    "        \n",
    "        self.policy_model_max_grad_norm = 1\n",
    "        self.value_model_max_grad_norm = float('inf')\n",
    "\n",
    "    def interact(self):\n",
    "        #start the environment.\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        experiences = []\n",
    "        episode_reward = 0\n",
    "        # interacting with the environment, continue \n",
    "        # until the pole falls (done == True) or max 200 steps. \n",
    "        for t in range(MAX_DUR):\n",
    "            # use the policy to select an action\n",
    "            action, is_explortionary, logpa, entropy = self.policy_model.full_forward_pass(state)\n",
    "            \n",
    "            self.actions_taken[action] = 1 + self.actions_taken.get(action, 0)\n",
    "\n",
    "            # interact with the environment.\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            self.logpa.append(logpa)\n",
    "            self.experiences.append((state, action, reward * (1-done)))\n",
    "            self.entropies.append(entropy)\n",
    "            self.episode_exploration[-1] += int(is_explortionary)\n",
    "            self.values.append(self.state_value_model(state))\n",
    "            self.rewards.append(reward)\n",
    "\n",
    "            episode_reward += 1\n",
    "            state = next_state\n",
    "            \n",
    "            if done: # the pole fell. \n",
    "                break\n",
    "        return experiences, episode_reward, done        \n",
    "\n",
    "    def optimize_model(self, experences):\n",
    "\n",
    "        sum_reward = 0\n",
    "        discnt_rewards = []\n",
    "        rewards = self.rewards\n",
    "        rewards.reverse()\n",
    "        \n",
    "        # calculate what are the returns for each step\n",
    "        # using discount. \n",
    "        returns, discounts = discount_rewards(rewards)\n",
    "        \n",
    "        #discounted_reward = torch.Tensor(returns)\n",
    "        discounts = torch.FloatTensor(discounts[:-1]).unsqueeze(1)\n",
    "        returns = torch.FloatTensor(returns[:-1]).unsqueeze(1)\n",
    "        \n",
    "        state_batch = torch.Tensor([s for (s,a,r) in self.experiences])\n",
    "        action_batch = torch.Tensor([a for (s,a,r) in self.experiences])\n",
    "\n",
    "        #train policy\n",
    "        pred_batch = self.policy_model.forward(state_batch)\n",
    "        prob_batch = pred_batch.gather(dim=1, index=action_batch.long().view(-1,1)).squeeze()\n",
    "\n",
    "        logpas = torch.cat(self.logpa)\n",
    "        entropies = torch.cat(self.entropies)\n",
    "        values = torch.cat(self.values)\n",
    "\n",
    "        value_error = returns - values\n",
    "        \n",
    "        # how wrong was our policy\n",
    "        policy_loss = -(discounts * value_error.detach() * logpas).mean()\n",
    "        entropy_loss = -(entropies.mean())\n",
    "        loss = policy_loss + self.beta * entropy_loss\n",
    "        \n",
    "        policy_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "    \n",
    "        torch.nn.utils.clip_grad_norm_(self.policy_model.parameters(), \n",
    "                                       self.policy_model_max_grad_norm)\n",
    "        self.policy_optimizer.step()\n",
    "        \n",
    "        value_loss = value_error.pow(2).mul(0.5).mean()\n",
    "        value_optimizer.zero_grad()\n",
    "        value_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.state_value_model.parameters(), \n",
    "                               self.value_model_max_grad_norm)\n",
    "        self.value_optimizer.step()\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        score = []\n",
    "        actions_taken = {}\n",
    "\n",
    "        scores_window = deque(maxlen=100)\n",
    "\n",
    "        for episode in tqdm(range(MAX_EPISODES)):\n",
    "\n",
    "            self.experiences = []\n",
    "            self.entropies = []\n",
    "            self.logpa = []\n",
    "            self.rewards = []\n",
    "            self.values = []\n",
    "            self.actions_taken = {}\n",
    "            self.episode_exploration.append(0.0)\n",
    "            experiences, rewards, done = self.interact()\n",
    "            scores_window.append(rewards)\n",
    "\n",
    "            score.append(rewards)\n",
    "            if done: \n",
    "                \n",
    "                next_value = 0 # if is_failure else self.state_value_model(state).detach().item()\n",
    "                self.rewards.append(next_value)\n",
    "                self.optimize_model(experiences)\n",
    "                \n",
    "\n",
    "            if episode % 100 == 0:\n",
    "                        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores_window)))\n",
    "                        print(self.actions_taken)\n",
    "            if np.mean(scores_window) >= 200:\n",
    "                print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(episode - 100,\n",
    "                                                                              np.mean(scores_window)))\n",
    "                torch.save(self.policy_model.state_dict(), 'policy_checkpoint.pth')\n",
    "                torch.save(self.state_value_model.state_dict(), 'state_value_checkpoint.pth')\n",
    "                break\n",
    "\n",
    "        \n",
    "        return score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the VPG Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8377ef807703421eaa67e342717c6419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\tAverage Score: 19.00\n",
      "{0: 8, 1: 11}\n",
      "Episode 100\tAverage Score: 28.09\n",
      "{1: 43, 0: 34}\n",
      "Episode 200\tAverage Score: 168.40\n",
      "{0: 101, 1: 99}\n",
      "Episode 300\tAverage Score: 187.61\n",
      "{1: 100, 0: 100}\n",
      "Episode 400\tAverage Score: 196.71\n",
      "{1: 99, 0: 101}\n",
      "\n",
      "Environment solved in 358 episodes!\tAverage Score: 200.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_DUR = 200\n",
    "MAX_EPISODES = 5000\n",
    "gamma = 0.99\n",
    "\n",
    "action_space = np.array([0,1])\n",
    "\n",
    "agent = Vpg(policy_model, \n",
    "            V,\n",
    "           policy_optimizer,\n",
    "           value_optimizer)\n",
    "\n",
    "score = agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12eb40040>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAGzCAYAAACW4Jt/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABLY0lEQVR4nO3dd3yV5f3/8dcnCWFvkD0UGQ6QrQwFNy7Q1rpntda6arWutrZqq9ZWv22t1qo/rXvUCaKCOAChCASRoWzZI6AoU1by+f1x39EYk5CTnJz7jPfz8TiPnHPd17nv950Tkg/3uC5zd0REREQk+WVFHUBEREREKkaFm4iIiEiKUOEmIiIikiJUuImIiIikCBVuIiIiIikiJ+oAidCsWTPv2LFj1DFERERE9mrGjBlfuHvz0pZlROHWsWNH8vLyoo4hIiIisldmtrysZTpVKiIiIpIiVLiJiIiIpAgVbiIiIiIpQoWbiIiISIpQ4SYiIiKSIlS4iYiIiKQIFW4iIiIiKUKFm4iIiEiKUOEmIiIikiJUuImIiIikCBVuIiIiIilChZuIiIhIioi8cDOzdmb2gZl9Zmafmtkvw/YmZjbOzBaFXxuH7WZm95vZYjObbWa9o90DERERkcSIvHAD9gDXu/uBwGHAlWZ2IHAz8J67dwbeC18DnAB0Dh+XAQ8lPrKIiIhI4uVEHcDd1wJrw+dbzGwe0AYYAQwNuz0JjAduCtufcncHPjKzRmbWKlyPiIgkoV0Fu1j05SIcjzpKle3fZH9q5dSKOkbktu/ezudffR51jISrl1uPjo06Rrb9yAu34sysI9ALmAq0KFaMrQNahM/bACuLvW1V2KbCTSRNjVk8hjcWvFGhvqd0PYVh+w+r5kQSq1+/82v+Oe2fUceIi3O7n8szP3om6hiRO/PlMxm9cHTUMRLuhP1P4K1z34ps+0lTuJlZPeAV4Fp332xm3y5zdzezmP6bZmaXEZxKpX379vGMKiIJ5O78fPTPWb9tPfVy65Xbd+uurbyx8A2WXbuMLEuGK0EEoNALefmzlxnacShX9rsy6jhV8uSsJxm5YCQ79+ykZk7NqONEZtOOTYxdPJYzDjqDnxz4k6jjJFTLei0j3X5SFG5mVoOgaHvW3V8Nm/OLToGaWStgfdi+GmhX7O1tw7bvcfdHgEcA+vbtm/rH5kUy1LTV01ixaQVPjHiCC3teWG7fZ2c/y3mvncekFZM4osMRCUooezNjzQzWbl3LPcfcw+kHnh51nCqpU6MOoxeO5v2l73NC5xOijhOZsUvGsrtwN1f3v5rB7QdHHSejRF64WXBo7TFgnrv/X7FFo4ALgT+HX0cWa7/KzF4ADgU26fo2kWh8sPQDZq6bWeby+rn1OeOgM2hYq2Glt/HSZy9RI6sGI7qN2GvfEd1GUKdGHZ6b85wKtySxaccmnp/7PNmWzUldToo6TpUdte9R1Mutx1Ozn+KA5gdEeq1TlEYtGEXT2k0Z0HZA1FEyTuSFGzAIOB+YY2afhG2/ISjY/mtmlwDLgTPCZW8BJwKLge3AxQlNK5LBtuzcwpjFYyj0Quaun8ufPvzTXt9z3TvXVenUwqrNqziu03E0qtVor33r5dbj1G6n8sLcF7j1iFtp06BNpbcrVffF9i/o+PeObNu9jaEdh9KkdpOoI1VZrZxanNT5JF6Y+wL//fS/zL9yPp2bdo46VkLtLtjNm4veZETXEWRnZUcdJ+NEXri5+yTAylh8dCn9HUjtiyREUpC7M/yF4YxfNv7bth8f8GMePvlhamTXKPU9C75YwOMzH2fzrs2V3u5hbQ/jmv7XVLj/74/4PSPnj+TsV87m/QvfJycr8l9zGevtRW+zbfc27jzqTs46+Kyo48TNgyc+yCldTuG8187j9fmvc8OgG6KOlFCTV07m6x1fM7zr8KijZCT9RhORH1i9eTWfbvj0e20fr/2Y8cvGc88x93BKl1OokV2DTo07UfxGopL6telHvzb9qjvu93Rt1pUHTnyAi0dezOiFozm126kJ3b58Z/Si0bSs15KbB9+cVjeLNK3TlHN7nMu9U+5l1MJRGVe4jVowitzsXI7rdFzUUTKSCjcR+Z6CwgKOfPJIFm1c9INl/dv05/oB1yf96ZHzepzHjeNu5Lk5z6lwi8jugt2MWTyGMw48I62KtuKGdxnOnz78Exu2baB53eZRx0mIPYV7GLVgFEfve/Re7/KW6pGe/5pEpNJGLRjFoo2LuO+4+5j808nfe4y/cHzSF20AOVk5nHnQmbyx8A0276z8aVqpnAenPUiTvzRh887NnNzl5KjjVJvhXYdT6IW8tSi6Mb0S6fk5z5P7x1yWfLVEp0kjpMJNRL7nvin30bFRR6459BoGthv4vUftGrWjjldh53Q/hx17dvDavNeijpJRCr2Qv/7vr7Rr0I7bhtyW1kNm9G7Vm9b1WzNq4aiooyTEk7OepE2DNtx77L1ccMgFUcfJWCrcRORbc9fPZfLKyVzd/+qUv6j/sLaHsW+jfXlu7nNRR8koHyz9gOWblnPrEbfyh6F/IDc7N+pI1cbMGN5lOGMXj2XHnh1Rx6lWm3Zs4v2l73P2wWdz/cDrqVOjTtSRMlZq/2YWkbh6etbT5GTlcF6P86KOUmVmxjndz+HuSXeTvzWfFvVa7P1NUinuzkufvcTIBSOZtnoajWo1yphrC0d0G8G/Z/ybsYvHpvXF+m8sfIPdhbsz5nNNZircRDLAl9u/ZPvu7eX2cZxn5jzDCfufwD5190lQsup1TvdzuPPDO3l+7vNce9i1UcdJW//55D9cMuoSWtRtQZsGbbi6/9UpdVq9Ko7seGQwfuCLp0YdpdrtU3cfDm1zaNQxMp4KN5E0Nzt/Nj3/3ROnYjO//f34v1dvoAQ6sPmBHNrmUG4cdyMLv1xI+4btuaLfFTSo2SDqaGmjoLCAuyfdTZ9WfZh66dSUuHklnmrm1OTVM17l47UfRx2l2g1oNyDjPt9kpMJNJM2NnB/MFvfQSQ9RI6v0gXKL1M2ty48P/HEiYiXM6HNGc9VbV/HYzMfYVbCL/3zyH0afPTrjRruvLi9/9jKLNy7m5Z+8nLF/1I/tdCzHdjo26hiSISyYiCC99e3b1/Py8qKOIRKJQY8PYnfBbqb9bFrUUSI3YdkETn/pdGrn1Oax4Y+VezovJyuHfq37ZWwxUhHuTq+He7GzYCefXvFp2o7XJpJoZjbD3fuWtkxH3ETS2FfffMVHqz7iN4N/E3WUpDCk4xDeOe8djnzySI57Zu8Xkt977L1cP/D6BCRLTW8vfptZ+bP4z4j/qGgTSRAVbiJpZNuubVz51pVs2rkJCG5KKPRChu0/LOJkyaNXq158esWnzPtiXrn9/jTxT9wz+R4u73s5dXPrJihdarl70t20b9iec7ufG3UUkYyhwk0kjYxdMpYnZz1Jt2bdvh0/65Qup3BoW90JVlybBm1o06BNuX3q1qjLwMcHcv/U+7nl8FsSlCx1fLj8QyatmMT9w+6nRnb5106KSPyocBNJIxOWTaB2Tm1mXT4rrQc+TYQB7QYwvGswF+XZ3c+mY6OOUUdKGu7OXZPuonmd5lzS+5Ko44hkFF2UIJJGxi8fz6D2g1S0xck/T/gnWZbFL978BZlwI9feuDvrtq7j1g9uZcziMdww8AaNoC+SYCrcRNLExm82Mid/DkM6DIk6Stpo37A9dx51J2MWj+H5uc9HHSdSqzev5sTnTqTVfa2488M7uaTXJbpxQyQCOlUqkiYmLp+I4yrc4uzKflfy3JznuOqtq/hsw2dcN+A6mtRuEnWshPpw+Yec/tLpbN21lTuG3kHf1n05fv/jdSepSAT0r04kTUxfPZ1sy6Zfm35RR0kr2VnZPH3a0/Ru1Zu7J93Nof/vUD7b8FnUsRJixaYV9HmkD0c8cQQNajYg72d53DrkVk7ofIKKNpGI6F+eSJqYvX423Zp1o1ZOraijpJ3OTTvz7gXvMvGiiWzasYk+j/Thl2//kqdmPZW21765Oz8f/XMWfLGAvx3/N6b/bDoHND8g6lgiGU+nSkXSxJz8OQxoNyDqGGltUPtBzP7FbK548woeynuI3YW7mbpqKg+c+ABmFnW8uHph7guMWTyGvx//d3552C+jjiMiIR1xE0kDm3ZsYvmm5fTYp0fUUdJey3otefXMV9n5u53cMPAG/pX3L56a9VTUseLqy+1f8ssxv6R/m/5c1f+qqOOISDEq3ETSwNz1cwHo0UKFW6KYGfcccw+HtDiEP0/+M4VeGHWkuLn53Zv5asdXPHrKo5qrVSTJqHATSQOz82cD0L1F94iTZBYz45bBtzD/i/m8Pv/1qOPExeKNi/nPJ//hyn5X6j8CIklI17iJpLg7JtzB07OfpmHNhrRr0C7qOBnn9ANPZ/8P9ueuD+/itG6nJfW1bks2LuG9pe+V2+e1+a+Rm53LzYNvTlAqEYmFCjeRFPb1jq+5bfxttG3Qlqv6X5XURUO6ys7K5qZBN/GzN37Gu5+/y7Gdjo06Uqk+2/AZh//ncDZ+s3GvfW8adBMt67VMQCoRiZUKN5EUNmnFJBznqdOeYmjHoVHHyVjn9zif28bfxl2T7kqqwq1oiqpZ+bO48PULyc3O5ePLPqZFvRZlvscwFW0iSUyFm0gKm7BsArnZuRza5tCoo2S0mjk1uX7A9Vz3znVMWTklKYZlWb9tPZe9cRkjF4wEoFuzbrx25mt0a9Yt4mQiUhW6OUEkhU1YPoFD2xxK7Rq1o46S8X7W52c0rd2UOybewbqt63ho+kMs3rg4sjyXj76cMYvH8Psjfs/Tpz3NtEunqWgTSQM64iaSorbs3MLHaz/mlsG3RB1FgHq59bhh4A3c/N7NtLqvFQDDuw5n5FkjE55l4zcbGb1wNFf3v5rbj7w94dsXkeqjwk0kRU1eOZkCL2BIR00qnyxuHHQjfVv3ZdKKSSz4cgH//fS/rNu6LuHXjL382cvsLtzNuT3OTeh2RaT66VSpSIqasGwCOVk5DGgb/fVUEjAzjt7vaP4w9A/8YcgfKPAC7vrwLubkz0lojufmPEfXpl3p1bJXQrcrItVPhZtIipqwfAL9Wvejbm7dqKNIKbo268oRHY7gn9P+SZ9H+vDF9i8Sst2Vm1YycflEzu1+roaHEUlDKtxEUtC2XduYvmY6QzroNGkye/3M13n6tKfZXbibMYvHJGSbL376Io5zdvezE7I9EUksFW4iKWjKqinsKdyj69uSXOPajTmn+zm0rNeSNxa+kZBtPjvnWfq36c/+TfZPyPZEJLFUuImkoCkrp2AYA9sNjDqK7EWWZXFS55MYs3gMqzavwt2rbVtvLnyTT9Z9wrnddVOCSLpS4SaSgvLW5tGlaRca1GwQdRSpgFO6nMLmnZtp97d2/GXyX6plG6s3r+aC1y+gZ8ueXNbnsmrZhohET4WbSAqasWYGfVr3iTqGVNDJXU7muR89R/d9uvPipy9WyzYemPYAm3Zs4r+n/5daObWqZRsiEj0VbiIpJn9rPqu3rKZPKxVuqSI7K5uzu5/NeT3OY+a6mazctDKu6y/0Qp6f+zzHdjqWzk07x3XdIpJcIi/czOxxM1tvZnOLtb1oZp+Ej2Vm9knY3tHMvim27N+RBReJyIy1MwBUuKWgEV1HAMEAuVt2bonb4/2l77N803Jd2yaSAZJh5oQngAeAp4oa3P3Moudmdh+wqVj/Je7eM1HhRJLNjDVB4darlQZXTTVdm3Wla9OuXPfOdVz3znVxXXedGnU4tdupcV2niCSfyAs3d59oZh1LW2bB6JFnAEclNJRIEpuxdoZuTEhhz/zoGSYsmxD39R7S8hDq5daL+3pFJLlEXrjtxeFAvrsvKta2r5nNBDYDv3P3D0t7o5ldBlwG0L59+2oPKpIoM9bO4PD2h0cdQyqpb+u+9G3dN+oYIpKiIr/GbS/OBp4v9not0N7dewHXAc+ZWamHHdz9EXfv6+59mzdvnoCoItVn887NDHtmGOOWjGPV5lW6vk1EJEMl7RE3M8sBfgR8+xfK3XcCO8PnM8xsCdAFyIskpEiCjJw/krFLxrJoY3DwWUOBiIhkpmQ+4nYMMN/dVxU1mFlzM8sOn+8HdAY+jyifSMK8Ov9VAD7/Kvhx792qd5RxREQkIpEXbmb2PDAF6Gpmq8zsknDRWXz/NCnAEcDscHiQl4HL3X1jwsKKRGDrrq2MWTyGzk2C8bl0Y4KISOaK/FSpu59dRvtFpbS9ArxS3ZlEksnYxWPZsWcH/xj2D8565Sz6t+kfdSQREYlI5IWbiJRv7JKxNKjZgGM7HcuEiybQom6LqCOJiEhEVLiJJDF3Z9zn4ziy45HkZOXQs2XPqCOJiEiEIr/GTUTKtuSrJSz7ehnH7nds1FFERCQJqHATSWLjlowD4NhOKtxERESFm0jSmrt+LrdPuJ3OTTp/e0epiIhkNhVuIknI3TntxdPIzspm5FkjCabtFRGRTKebE0SS0Kz8WSzeuJjHhz/OAc0PiDqOiIgkCR1xE0lCr89/nSzL4uQuJ0cdRUREkogKN5Ek9Pr81xnUbhDN6zaPOoqIiCQRFW4iSWbpV0uZlT+LU7udGnUUERFJMircRJLMyAUjARjRdUTESUREJNmocBNJMq/Pf52D9zmYTk06RR1FRESSjAo3kSTyxfYv+HDFh5za9dSoo4iISBJS4SaSJKatnsbAxwZS6IX86IAfRR1HRESSkAo3kSRx96S7+WrHV7x+5uv0atUr6jgiIpKEVLiJJIm8NXkc1+k4RnTTTQkiIlI6FW4iSWD9tvWs2ryKPq36RB1FRESSmAo3kSQwY80MABVuIiJSLhVuIkkgb00ehunaNhERKZcKN5EkMG3NNLo07UKDmg2ijiIiIklMhZtIhAoKC7jo9YsYvXA0R+97dNRxREQkyalwE4nQq/Ne5clZT3LDwBv427C/RR1HRESSXE7UAUQylbtz96S76dK0C3cffTfZWdlRRxIRkSSnwk0kIs/PfZ6Z62by2PDHVLSJiEiF6FSpSAQ+WfcJl466lIHtBnJej/OijiMiIilChZtIBG6fcDv1cuvx6hmvkpudG3UcERFJESrcRBJsy84tvL3obc4++Gxa1GsRdRwREUkhKtxEEuzNRW+ys2Anpx94etRRREQkxahwE0kgd+fJWU/Sql4rBrUfFHUcERFJMTHfVWpmA4CjgdZArTK6ubtfUpVgIulk666tPDXrKSatmMSYxWO466i7yDL9v0lERGJT4cLNzGoCLwKnFDWV090BFW6S8Xbs2cGaLWu4dNSlfLDsAwzjhoE3cPPgm6OOJiIiKSiWI263AcOBrcDTwHxgczVkEkl57s7Ln73MNWOuYd3WdQA8eeqT/OTAn1C7Ru2I04mISKqKpXA7E9gG9HP3BdWURyTl5W/N54RnT2Dmupn0bNmTPx35J7o166Zr2kREpMpiKdxaAx+oaBMp3+MzH/92RoTze5xPjewaUUcSEZE0EUvhtgGdGhXZq5c+e4nD2h7GT3v9NOooIiKSZmK5re0tYKCZaX5TkTIs3riYmetm8pMDfxJ1FBERSUOxFG63hl8fCO8wFZESXp33KoAG1xURkWoRy9Gzy4GxwM+AYWb2PrACKCylr7v7HyuyUjN7HDgZWO/uB4dtt4Xb2RB2+427vxUuu4VgqJEC4Bp3HxvDPohUq8krJ9O1aVfaN2wfdRQREUlDsQ4H4gTjt7UHLiqlT9FyBypUuAFPAA8AT5Vo/5u731u8wcwOBM4CDiK4WeJdM+vi7gUV3JZItXF3pq6aynGdjos6ioiIpKlYCrfbqyOAu080s44V7D4CeMHddwJLzWwx0B+YUh3ZRGKxavMq8rflc2ibQ6OOIiIiaarChZu7V0vhVo6rzOwCIA+43t2/AtoAHxXrsyps+wEzuwy4DKB9e522kuo3dfVUAPq36R9xEhERSVfJOlniQ0AnoCewFrgv1hW4+yPu3tfd+zZv3jzO8UR+aNrqaeRm59KjRY+oo4iISJqq9NAeZtaK7452rXb3tfGJBO6eX2w7jwKji7YDtCvWtW3YJhK56Wumc0iLQ6iZo5uuRUSkesR8xM3MfmZmCwhOU04NH6vMbL6ZXRqPUGFRWOQ0YG74fBRwlpnVNLN9gc7AtHhsU6Qq3J1Z62bRq2WvqKOIiEgai+mIm5k9AZzPd3eOrgkXtQa6AA+b2SB3vziGdT4PDAWamdkq4A/AUDPrGW5jGfBzAHf/1Mz+C3wG7AGu1B2lkgzWbFnDVzu+0mlSERGpVhUu3MzsbOACYD1BcfVEeHcn4YC8FxEMGXKBmY119xcqsl53P7uU5sfK6X8ncGdFc4skwuz82QB0b9E94iQiIpLOYjlV+jNgF3CUuz9cVLQBuPtOd38YOJrgSNhl8Y0pkty+Ldz2UeEmIiLVJ5bCrScw3t0/K6tDuOyDsK9Ixpizfg7tGrSjce3GUUcREZE0FkvhVgfYWIF+G4HalYsjkppm58/WaVIREal2sRRuq4H+ZmZldQiX9eO7mxZE0t43u79h3hfz6LGPbkwQEZHqFUvhNhbYF/irmWWXXGhmWcA9wH7AmPjEE0l+U1dPZU/hHga2Gxh1FBERSXOxDAfyZ4IJ3n8FnGZmzwFLCYbs2A84m6Cw+zrsK5IRJiybgGEc3uHwqKOIiEiai2Wu0hVmdiLwX4IC7TcluhiwEjjD3VfGL6JIcpuwfAKHtDyERrUaRR1FRETSXEwD8Lr7R2bWGfgJMIRiU14BE4CXig8TIpLudu7ZyZRVU/h5n59HHUVERDJAzHOVhoXZM+FDJKNNXzOdHXt2MKTDkKijiIhIBoh5rlIR+c64JePIsiyGdhwadRQREckAKtxEqmDc5+Po27qvBt4VEZGEKPNUqZl9TnDH6DHuvjR8XVHu7p2qnE4kiW3asYlpq6dx8+Cbo44iIiIZorxr3DoSFG41ir2uKK9kHpGU8cGyDyjwAo7d79ioo4iISIYor3DbN/y6usRrESG4vq1ujboMaDcg6igiIpIhyizc3H15ea9FMt24z8cxpOMQcrNzo44iIiIZosI3J5jZEWbWpQL9OpvZEVWLJZLcln+9nEUbF+k0qYiIJFQsd5WOB26qQL8bgQ8qlUYkRYz7fByACjcREUmoWIcDsWpJIZJi3l78Nq3rt+bA5gdGHUVERDJIdYzjtg/wTTWsVyQpfP7V54ycP5KzDjoLM/1fRkREEqfcKa9KuVatZTnXr+UABwDHAfPikE0kKf118l/JsiyuG3Bd1FFERCTD7G2u0vF8f0y248NHeQx4uAqZRJLWlp1beGLWE1xwyAW0adAm6jgiIpJh9la4TeS7wm0IsB6YX0bfXQRjvr3m7m/EJ55Icnlz0Zvs2LODCw+5MOooIiKSgcot3Nx9aNFzMysE3nb3n1Z3KJFk9cq8V2hRtwUD2w2MOoqIiGSgvR1xK+5IYF11BRFJdtt3b+etRW9xQY8LyM7KjjqOiIhkoAoXbu4+oTqDiCS78cvGs333dk474LSoo4iISIaK5Yjb95hZQ6ABZYzt5u4rKrtukWT03ufvUTO7Joe3PzzqKCIikqFiKtzMrAnwR+DHQPNyunqs6xZJdu8tfY+B7QZSu0btqKOIiEiGimWu0sbAVOByoAnBILvGd9e9FR15WwGsjGNGkch9sf0LZuXP4uh9j446ioiIZLBYZk64CegE/AdoCLwMuLu3AeoDPwc2ApPcfd94BxWJ0gdLg+l3j9r3qIiTiIhIJoulcDsF2ABc6e7fUGxgXnff7u6PAicAZ5vZFfGNKRKt95e+T/3c+vRr0y/qKCIiksFiKdw6AnnuvjN87QBm9u24CO6eB0wCLolXQJFk8N7S9ziiwxHkZOnSTRERiU4shVsBsLnY623h12Yl+q0BOlcllEgyWblpJYs2LtL1bSIiErlYCrc1QLtir5eFX/uU6HcAsBORNPH+0vcBOHo/FW4iIhKtWAq3j4FuxU6NvkdwJ+mfzewAM6tvZjcBhwCz4pxTJDJjl4ylWZ1mHLzPwVFHERGRDBdL4fY2wTAgwwDc/RPgDeBgYC7wNXAXwbVvd8QzpEhUln61lJc+e4mzDjqLLIvln4uIiEj8xfKX6HmCU6XFp746B3gQWA/sISjgznD3iXFLKBKhOz+8k2zL5ubBN0cdRUREJKa5SvcAq0u0bQOuDh8iaWNP4R7e/fxdHp/5ONcceg1tGrSJOpKIiEhMMyf8n5n9Pt4BzOxxM1tvZnOLtf3VzOab2Wwze83MGoXtHc3sGzP7JHz8O955RJ6f8zy5f8xl+PPDOXifg7nzqDujjiQiIgLEdqr0aoIbD+LtCcLr5ooZBxzs7j2AhcAtxZYtcfee4ePyasgjGe6NhW/QqFYjzjz4TF4/63Xq5taNOpKIiAgQ20Tw6wiuY4srd59oZh1LtL1T7OVHwOnx3q5IWSatmMRxnY7j6dOejjqKiIjI98RyxO1dYJCZJXro+J8S3NFaZF8zm2lmE8zs8LLeZGaXmVmemeVt2LCh+lNKWlj+9XJWbl7J4PaDo44iIiLyA7EUbn8AagP/NrOEnDsys98SHOV7NmxaC7R3917AdcBzZtagtPe6+yPu3tfd+zZv3jwRcSUNTFoxCUCFm4iIJKVYjp5dRHDk62JguJm9CywHvimlr7v7H6sSzMwuAk4GjnZ3D1e6k3BWBnefYWZLgC5AXlW2JVLkwxUf0qBmA7rv0z3qKCIiIj8QS+F2G8HgukYwP+lZpfQpWu5ApQs3MxsG3AgMcfftxdqbAxvdvcDM9iOYE/Xzym5HpLhCL2T0wtEcte9RZGdl7/0NIiIiCRZL4XYHQUEWV2b2PDAUaGZmqwhOyd4C1ATGmRnAR+EdpEcAd5jZbqAQuNzdN8Y7k2SmqaumsnrLau454J6oo4iIiJQqlgF4b6uOAO5+dinNj5XR9xXglerIIfLyZy+Tm53LyV1OjjqKiIhIqTT5okjotfmvcex+x9KwVsOoo4iIiJRKhZsIsGbLGpZ+vZRj9jsm6igiIiJlqvCp0hinu6ryXaUiiTR11VQADmt7WMRJREREylbZu0pLKn7TQpXvKhVJtKmrp1IjqwY9W/aMOoqIiEiZYincbi+jPQvoQHBnaHvgcWBl1WKJJNZHqz6iZ8ue1MqpFXUUERGRMsVyV2lZhRsAZlYL+DfBhPG9q5hLJGH2FO4hb00eF/e8OOooIiIi5YrbzQnuvgO4HMgG/hSv9YpUtykrp7Bt9zYGtBsQdRQREZFyxfWu0rB4ywNOjOd6RarTg9MfpGHNhgzvOjzqKCIiIuWqjuFAcgimxBJJemu2rOGVea/w014/pV5uvajjiIiIlCuuhZuZdQEOB1bHc70i1eXFuS+yp3APV/S7IuooIiIiexXLOG4XlLO4HtANOB+oDbxQxVwiCfHhig/Zr/F+7N9k/6ijiIiI7FUsw4E8QfmTzBeN7zaasocOEUka7s7klZMZtv+wqKOIiIhUSCyF21OUXbjtIjg9+p67T65yKpEEWLxxMeu3rWdQu0FRRxEREamQWMZxu6gac4gk3OSVwf8xBrcfHHESERGRitEk85KxJq2YRONajenWrFvUUURERCokllOlmFkW0BFoChQCG4Fl7l7etW8iSWnC8gkc3uFwskz/fxERkdRQob9YZnaEmY0CvgYWAR8B04DFwFdm9qqZadh5SRmrN69m8cbFDOkwJOooIiIiFbbXws3M/gp8AJxEMOyHlXg0AE4FJpnZndWWVCSOJiyfAMDQjkOjDSIiIhKDcgs3M7sWuD58+QpBgdYWqAXUAdoDpwGvhn1uNrOrqiOoSDxNWDaBhjUbckiLQ6KOIiIiUmFlXuNmZg2BO4HdwOnu/kYp3VaFj5FmNhx4GbjbzJ5y983VEVgkHoqub8vOyo46ioiISIWVd8TtHIJZEO4qo2j7HncfRVDo1QHOik88kfhbu2UtC75coOvbREQk5ZRXuA0lONp2fwzrux8oAI6qQiaRajVx+UQAFW4iIpJyyivcegBz3f2riq4s7DsnfK9IUhq/bDz1c+vTq1WvqKOIiIjEpLzCrTmwvBLrXAbsU6k0IgkwYfkEBrcfTE5WTMMYioiIRK68wq0BsKkS69wC1K9cHJHqlb81n3lfzNMwICIikpLKK9xyKHtS+fI4Mc7IIJIour5NRERSmeb6kYwyYfkE6taoS+9WvaOOIiIiErO9HRk73cyGxrjOZpWLIlL9xi8bz+D2g6mRXSPqKCIiIjHbW+FWL3zESpPOS1LJW5PHe5+/x6cbPuXc7udGHUdERKRSyivcjkxYCpFq9tv3f8s7S94BND+piIikrjILN3efkMggItWloLCAKSuncHyn4zmu03Ec2vbQqCOJiIhUiu7+lLQ3Z/0ctuzawvk9zufcHjpNKiIiqUt3lUram7xiMgCD2w+OOImIiEjVqHCTtDdp5STa1G9D+4bto44iIiJSJSrcJK0VeiETlgVTXJlZ1HFERESqRIWbpLXpq6ezdutaTu5yctRRREREqkyFm6S11+e/Tk5WDid1PinqKCIiIlWWFIWbmT1uZuvNbG6xtiZmNs7MFoVfG4ftZmb3m9liM5ttZpq7SMr02vzXGNpxKI1rN446ioiISJUlReEGPAEMK9F2M/Ceu3cG3gtfA5wAdA4flwEPJSijpJglG5ew4MsFjOg6IuooIiIicVGpws3MDjKzS83sFjMbXqw9y8xyY12fu08ENpZoHgE8GT5/Eji1WPtTHvgIaGRmrWLeCUl7k1ZMAuDIjpoERERE0kNMhZuZtTez94HZwMPAn/iuoAK4FPjGzI6OQ7YW7r42fL4OaBE+bwOsLNZvVdhWMutlZpZnZnkbNmyIQxxJNZNWTKJxrcYc0PyAqKOIiIjERYULNzNrBkwEhgJzCU5Rlhxf4SWgkOCoWNy4uxPjxPXu/oi793X3vs2bN49nHEliwY9KYNLKSQxqP4gsS5YrAkRERKomlr9otwDtgXuAnu5+VckO7v4VwdG4eAxRn190CjT8uj5sXw20K9avbdgmwrFPH0vPf/dk5PyRzP9iPoPbabYEERFJH7EUbqcAS4HfePHDGj/0OdC6SqkCo4ALw+cXAiOLtV8Q3l16GLCp2ClVyWDf7P6G8cvGMyt/Fqe+eCoAg9oPijaUiIhIHMUyyXw7YPReijaAPUBMYy+Y2fMEp2Cbmdkq4A/An4H/mtklwHLgjLD7W8CJwGJgO3BxLNuS9DVn/RwKvIAnRjxB7Rq1yd+az8B2A6OOJSIiEjexFG7fAI0q0K8j8HUsIdz97DIW/eAmh7BwvDKW9Utm+HjtxwAM7TiUDo06RJxGREQk/mI5VToX6GNmDcvqYGZtgEOAj6saTCRWH6/9mCa1m2gyeRERSVuxFG7PERxxe7i0sdrMLAu4H6gJPBOXdCIx+Hjtx/Ru1VuTyYuISNqKpXD7f8BkgmvN5pnZ/WH7wWZ2DzAPOA2YQFDkiSTM1l1bmbN+Dr1bagY0ERFJXxW+xs3d95jZicCjBMVb0XAgfcMHwOvAhRW4gUEkbgq9kPNfO589hXsY0U3TW4mISPqK5eYE3H0LcJaZ3U4wZ+h+QDbBTAZvu/vM+EcUKVuhF3L56Mt5ff7r3D/sft1FKiIiaS2mwq2Iu88jODUqEomxi8dy07s3Me+Leewq2MVvBv+Gq/r/YExoERGRtFKpwk0kSl9s/4KTnz+Zjo06ck3/azh4n4O54JALdFOCiIikvTILNzOr0pgK7r6iKu8XKcvHaz9mT+EeHj75YY7a96io44iIiCRMeUfclhHjxO7F+F7WLVJpM9cGl1L2bNkz2iAiIiIJVl5xtYLSC7fiQ9JvCr8WH5R3eVVDiZTn43Uf06FhB5rUbhJ1FBERkYQqcxw3d+/o7vsWPYBOwAxgA3AN0NjdG7t7Y4K5Sa8G8oG8sK9ItZi5dia9WvWKOoaIiEjCxTIA7/XAScBQd3/A3YuOtuHum9z9QeAo4BTghvjGFAls2bmFRRsX0aulCjcREck8sRRuFwHjw6FAShUu+wC4sIq5REo1Y+0MABVuIiKSkWIp3PYFvqpAv6+BjpUJI7I39/7vXhrWbMjhHQ6POoqIiEjCxVK4bQYGmll5Q4jkAAPCviJx9eHyD3lz0ZvcPPhmGtVqFHUcERGRhIulcHsHaAc8amb1Sy40s3rAw2GfsfGJJxJwd2569yZa12/NNYdeE3UcERGRSMQy1trvCOYnvQAYYWajgaXhso7AyUAjYCPw+/hFFIFRC0YxZdUUHj75YerUqBN1HBERkUhUuHBz9xVmNgR4GugFnMd347wVzTX0CXC+u2ssN4mrv/zvL3Ru0pmf9vpp1FFEREQiE9PsBu7+GdDHzAYDQ4C24aLVwAR3/zDO+UTYsWcH01dP51eH/YqcLE3IISIimatSfwXdfRIwKc5ZREr1ybpP2F24m0PbHhp1FBERkUjFcnOCSCSmrpoKwGFtD4s4iYiISLRiPuJmZs2AnwFDgTZh82qCgXcfc/cNcUsnAny0+iPaNmhL6/qto44iIiISqZgKNzM7AXiWYFJ5K7boQOAY4AYzO8/d345fRMl0U1dN1dE2ERERYjhVambdgFcIhvyYCvwcODZ8/Dxsawy8HPYVqbIZa2aw9OulDG43OOooIiIikYvlGrebgVrADe4+0N0fdff3wsej7j4Q+DVQG7ipOsJK5rlj4h00qtWIi3peFHUUERGRyMVSuB0FzHX3+8rq4O7/B8wFjq5qMJHZ+bMZtWAUvzrsVzSs1TDqOCIiIpGLpXBrAcyuQL85wD6ViyPynX9N/xe1cmpxdf+ro44iIiKSFGKdZL7NXntBa2BL5eKIBLbu2sqzc57lzIPOpHHtxlHHERERSQqxFG55wGAzG1RWBzMbCBwOTK9qMMlsL859ka27tvLzPj+POoqIiEjSiKVwewDIBt42szvMrJOZ5ZhZdvj8duBtgmFCHqiOsJI53l/2Pq3rt9YwICIiIsVUuHBz9zeBe4B6wG+BhcA3wI7w+e+A+sA97v5W/KNKJpmxZgb9WvfDzPbeWUREJEPENOWVu98CnAyMB3YRHIHLDp9/AJzs7r+Jc0bJMJt3bmbhlwvp06pP1FFERESSSsxTXoVH094ys2ygadj8pbsXxDWZZKyZa2fiOH1aq3ATEREpLubCrUhYqK2PYxYRAGasnQGgI24iIiIlVLpwK87MjgEOAZYDr+nom1TW1zu+5u3Fb9O2QVta1GsRdRwREZGkEstcpT8zs8/MbHCJ9keBscBfgBeBd82sRnxjSibYXbCbXg/34t3P3+X8HudHHUdERCTpxHJzwo+AlgSTyQNgZgOAS4CtwLPAUuAI4Jw4ZpQM8emGT1n29TIeOukh7jr6rqjjiIiIJJ1YCrcDCeYq3V2s7SzAgbPd/QLgUGA7cHFVg5lZVzP7pNhjs5lda2a3mdnqYu0nVnVbkhymrw7GbT5mv2MiTiIiIpKcYrnGrRnwvxJtRwBfFY3b5u5fmtmHQPeqBnP3BUBPgPAO1tXAawRF4d/c/d6qbkOSy/Q102lUqxGdGneKOoqIiEhSiuWIWxZQs+iFmdUBDgYml+j3JUGRF09HA0vcfXmc1ytJZPqa6fRt3VeD7oqIiJQhlsJtFeERsNCxBIPvlizcGgFfVSnVD50FPF/s9VVmNtvMHjezUmcgN7PLzCzPzPI2bNgQ5zgSb9/s/oY5+XPo17pf1FFERESSViyF21igg5k9aGbDCaa/cmB0iX49gRXxiQdmlgsMB14Kmx4COoXbWQvcV9r73P0Rd+/r7n2bN28erzhSTWaum0mBF6hwExERKUcshdudBAPu/oLgWrMuwHPu/llRBzPrBbThh9fCVcUJwMfung/g7vnuXuDuhcCjQP84bksiMm7JOAzjiA5HRB1FREQkaVX45gR3XxsWZj8DWgDTgKdLdDsYGAm8EreEcDbFTpOaWSt3Xxu+PA2YG8dtSUTGLBlD/zb9aVqn6d47i4iIZKiYZk5w93XAH8tZ/jQ/LOYqzczqElxL9/NizX8xs54Ep2mXlVgmKejL7V8ybfU0fnf476KOIiIiktTiMuVVdXH3bXw3kX1Rm4bUTzPvfv4uhV7IsP2HRR1FREQkqcVyjZtItXh/6fs0rNmQfm10Y4KIiEh5yjziZmYFBKcjD3T3heHrinJ3T+qjeZI8Jq6YyOD2g8nJ0o+MiIhIeco74mYlllsMDx3JkwpZv20987+Yr7tJRUREKqDMQxzunlXea5F4mLh8IoAKNxERkQpQMSaRmrh8InVq1KF3q95RRxEREUl6KtwkMoVeyKgFozi8/eHkZudGHUdERCTpVepqcDMbAAwF2oZNq4Hx7h7PGRMkzY1bMo7lm5bzl2P/EnUUERGRlBBT4WZmnQkG2C0at8HCrx4uzwMucPcFcUsoaevRjx+lWZ1mjOg6IuooIiIiKaHChZuZtQMmEkx3tRl4g2DmAoCOwMkEBd0EM+vv7nGbaF7Szze7v2HUglFc2e9KaubUjDqOiIhISojliNsfCYq2p4Fr3H1T8YVm1gC4H7gAuAO4KE4ZJQ3lrcljd+Fujt7v6KijiIiIpIxYbk4YBqwALilZtAG4+2bgUmBl2FekTFNWTQHgsLaHRZxEREQkdcRSuDUE/ufue8rqEC77H9CgqsEkvf1v5f/o3KQzzeo0izqKiIhIyoilcFsKNK5Av4bA8srFkUzg7kxZNYUB7QZEHUVERCSlxFK4PQUMNbOuZXUws27AUQTXwYmUaunXS1m/bT0D2qpwExERiUUshdtfgTeB8Wb2i/BmBADMrL6ZXQ68D4wG/hzfmJJOZq6dCUC/1v320lNERESKi+Wu0kXh1xbAA8ADZvZ12NaoWL8+wGIzK9aEu3unSmaUNDMrfxZZlsVB+xwUdRQREZGUEkvh1rHY86KqrLRr3jqU0uYxbEfS3Oz82XRt2pVaObWijiIiIpJSYinc9q22FJJRZufPpn+b/lHHEBERSTkVLtzcXXeKSpVt3rmZpV8v5dLel0YdRUREJOXEcnOCSJXNyZ8DQI8WPSJOIiIiknrKLNzM7Agz6xLrCs3sGDO7pmqxJF3Nyp8FqHATERGpjPKOuI0HbiptgZltNLN/lvG+c4G/VTGXpKlpq6fRrE4z2jVoF3UUERGRlLO3U6VWRnsjoG58o0gmmLJqCgPaDqDEcDEiIiJSAbrGTRLmy+1fsvDLhZoxQUREpJJUuEnCfLTqIwDNUSoiIlJJKtwkYaasmkK2ZWuqKxERkUpS4SYJM231NLq36E7dXF0eKSIiUhkq3CRhZufPpmfLnlHHEBERSVl7mzmhpZkdEeOyllXMJGlow7YN5G/Lp/s+3aOOIiIikrL2VrgdHz5K8nKWifzAnPXBjAkq3ERERCqvvMJtBUGBJlJls/NnA9C9hQo3ERGRyiqzcHP3jgnMIWluTv4cmtVpRou6LaKOIiIikrJ0c4IkxJz1c+jRoodmTBAREakCFW5S7fYU7uHTDZ/q+jYREZEqUuEm1W7+F/PZvns7fVr1iTqKiIhISlPhJtVuxpoZAPRt3TfiJCIiIqlNhZtUu7w1edTLrUeXpl2ijiIiIpLS9jaOW+TMbBmwBSgA9rh7XzNrArwIdASWAWe4+1dRZZTy5a3No1fLXmRnZUcdRUREJKWlyhG3I929p7sXnWu7GXjP3TsD74WvJQntKdzDJ+s+0WlSERGROEiVwq2kEcCT4fMngVOjiyLl+WzDZ+zYs0OFm4iISBykQuHmwDtmNsPMLgvbWrj72vD5OuAHo7qa2WVmlmdmeRs2bEhUVikhb00eoBsTRERE4iHpr3EDBrv7ajPbBxhnZvOLL3R3N7MfTM3l7o8AjwD07dtXU3dFJG9NHg1qNmD/JvtHHUVERCTlJf0RN3dfHX5dD7wG9AfyzawVQPh1fXQJpTx5a/Lo3ao3WZb0P2oiIiJJL6n/mppZXTOrX/QcOA6YC4wCLgy7XQiMjCahlGdXwS5m58+mbyudJhUREYmHZD9V2gJ4LZzfMgd4zt3HmNl04L9mdgmwHDgjwoxShk/Xf8rOgp26vk1ERCROkrpwc/fPgUNKaf8SODrxiSQWH636CIA+rTXVlYiISDwk9alSSW1Pz36aA5odQKfGnaKOIiIikhZUuEm1+HT9p0xZNYVLe19KeKpbREREqkiFm8TdnsI9/OnDP1Ejqwbn9zg/6jgiIiJpI6mvcZPUUVBYwEN5D/HX//2VXQW7WLd1Hb87/Hc0r9s86mgiIiJpQ4WbxMU9k+/ht+//liM6HEGreq04pcspnNvj3KhjiYiIpBUVblJlX2z/gnsm38OIriN47czXdE2biIhINdE1blJlf570Z7bu2sqdR92pok1ERKQaqXCTKlm1eRUPTHuACw65gIP2OSjqOCIiImlNhZtUye3jb8dxbhtyW9RRRERE0p4KN6m02fmzefyTx7mi7xV0aNQh6jgiIiJpT4WbVIq7c93Y62hUqxG3Drk16jgiIiIZQXeVSqVMWjGJ95a+xz+G/YMmtZtEHUdERCQj6IibVMq/8v5Fo1qNuLT3pVFHERERyRgq3CRm+VvzeeWzV7jwkAupU6NO1HFEREQyhgo3idl9U+5jd+FuLu97edRRREREMooKN4nJ4o2L+ftHf+einhfRrVm3qOOIiIhkFBVuEpMbx91IbnYudx51Z9RRREREMo4KN6mwD5Z+wGvzX+M3h/+G1vVbRx1HREQk46hwkwq75b1b6NCwA7867FdRRxEREclIKtykQtZuWcvU1VP5Rd9fULtG7ajjiIiIZCQVblIh7yx5B4Dj9z8+4iQiIiKZS4WbVMg7n7/DPnX3oUeLHlFHERERyVgq3GSvCr2QcUvGcVyn48gy/ciIiIhERX+FZa/GLRnHhu0bOGH/E6KOIiIiktFUuMle3TP5HtrUb8OPD/hx1FFEREQymgo3Kdf01dP5YNkHXDfgOmrm1Iw6joiISEZT4SblemrWU9TKqcWlvS+NOoqIiEjGU+EmZSooLODleS9zUueTaFCzQdRxREREMp4KNynTpBWTWLd1HWccdEbUUURERAQVblIGd+cfU/9B7ZzanNT5pKjjiIiICJATdQBJTg/PeJjX5r/Gn4/+M3Vz60YdR0RERNARNynFjj07uOW9Wzhmv2O4YdANUccRERGRkAo3+YHX57/O1zu+5uZBN2umBBERkSSiv8ryA4/PfJwODTtw5L5HRh1FREREilHhJt/zr+n/4t3P3+XinhfraJuIiEiS0V9m+dZbi97iyreu5OQuJ/Prgb+OOo6IiIiUoLtK5VsvzH2BJrWb8MoZr1Aju0bUcURERKSEpD3iZmbtzOwDM/vMzD41s1+G7beZ2Woz+yR8nBh11nSwp3APby56k5M6n6SiTUREJEkl8xG3PcD17v6xmdUHZpjZuHDZ39z93gizpZ1JKyax8ZuNjOg6IuooIiIiUoakLdzcfS2wNny+xczmAW2iTZWeCr2Qv3/0d2pm1+T4/Y+POo6IiIiUIWlPlRZnZh2BXsDUsOkqM5ttZo+bWeMy3nOZmeWZWd6GDRsSFTXluDs3jruRkQtGcudRd1Ivt17UkURERKQMSV+4mVk94BXgWnffDDwEdAJ6EhyRu6+097n7I+7e1937Nm/ePFFxU84fxv+B+6bcx5X9ruS6AddFHUdERETKkdSFm5nVICjannX3VwHcPd/dC9y9EHgU6B9lxlQ2acUk/jjxj1zc82LuP+F+zCzqSCIiIlKOpC3cLKgiHgPmufv/FWtvVazbacDcRGdLB+7OLe/dQst6LXngxAc02K6IiEgKSNqbE4BBwPnAHDP7JGz7DXC2mfUEHFgG/DyKcKnuzUVvMmnFJB488UHq1KgTdRwRERGpgKQt3Nx9ElDaubu3Ep0l3ewq2MV1Y6+ja9OuXNr70qjjiIiISAUlbeEm1edf0//Foo2LePvct8nNzo06joiIiFSQLmzKMAWFBfz9o78zpMMQhu0/LOo4IiIiEgMVbhnmjYVvsHzTcq459Jqoo4iIiEiMVLhlkF0Fu7jrw7to16Adw7sOjzqOiIiIxEjXuGWQ68Zex/Q103nhxy+Qk6WPXkREJNXoiFuGmJM/hwenP8i1h17LmQefGXUcERERqQQVbhni/qn3UzunNrcOuTXqKCIiIlJJKtwywIZtG3hmzjOc3+N8mtRuEnUcERERqSQVbmmu0Au5ZNQl7Cncw7WHXRt1HBEREakCXaGe5h6c9iBvLHyDfwz7Bwc0PyDqOCIiIlIFOuKWxjZ+s5Hfj/89x3U6jqv7Xx11HBEREakiFW5pauuurVzz9jVs3rmZe4+9F7PSpn0VERGRVKJTpWlm3oZ5PDbzMZ6a9RQbtm/glsG30L1F96hjiYiISByocEsTizcu5vp3rmfUglHkZOUwvOtwfj3g1wxoNyDqaCIiIhInKtxSWP7WfF6d9yqfrPuEJ2Y9QW52Ln888o9c1ucy9qm7T9TxREREJM5UuMWBu3Pv/+6lT+s+7Nd4P3KycqiVU4umtZvG9dqy3QW72bprK5t3buYfU//BA9MeYHfhbmrl1OKc7udw11F30ap+q7htT0RERJKLCrc4WLNlDTe9exOOf6+9fm59ujTtQuv6rSn0Qrbt3saIriM4sPmBbNu1jbVb17Jmyxo2bNtAbnYun274lJ0FOxnaYSi7CnaxaecmNu3cRKEXsmnHJj5Y9gF7Cvd8u/5Lel3CdQOu44BmB+jmAxERkQxg7r73Ximub9++npeXV63b2LRjE1NWTWHd1nUUFBawdddWlny1hIVfLiR/Wz4ABYUFzFk/53vvy7IsmtVpxs49O+nQqAM5WTl8vPZjauXUomHNhjSs1ZAsyyLbsjm+0/G0a9iOern16N2qN71b9a7WfRIREZHEM7MZ7t63tGU64hYnDWs1ZNj+w/bab8nGJazdupY6NerQql4r9qm7D9lZ2d/rs6dwDzlZ+mhERETk+1QdJFinJp3o1KRTuX1UtImIiEhpNACviIiISIpQ4SYiIiKSIlS4iYiIiKQIFW4iIiIiKUKFm4iIiEiKUOEmIiIikiJUuImIiIikCBVuIiIiIilChZuIiIhIilDhJiIiIpIiVLiJiIiIpAgVbiIiIiIpQoWbiIiISIpQ4SYiIiKSIlS4iYiIiKQIc/eoM1Q7M9sALE/AppoBXyRgO8lG+51ZtN+ZJ1P3XfudWZJpvzu4e/PSFmRE4ZYoZpbn7n2jzpFo2u/Mov3OPJm679rvzJIq+61TpSIiIiIpQoWbiIiISIpQ4RZfj0QdICLa78yi/c48mbrv2u/MkhL7rWvcRERERFKEjriJiIiIpAgVbiIiIiIpQoVbHJjZMDNbYGaLzezmqPNUJzNbZmZzzOwTM8sL25qY2TgzWxR+bRx1zngws8fNbL2ZzS3WVuq+WuD+8Gdgtpn1ji551ZSx37eZ2erwc//EzE4stuyWcL8XmNnx0aSuOjNrZ2YfmNlnZvapmf0ybE/rz7yc/U7rz9zMapnZNDObFe737WH7vmY2Ndy/F80sN2yvGb5eHC7vGOkOVFI5+/2EmS0t9nn3DNvT4ue8iJllm9lMMxsdvk69z9vd9ajCA8gGlgD7AbnALODAqHNV4/4uA5qVaPsLcHP4/GbgnqhzxmlfjwB6A3P3tq/AicDbgAGHAVOjzh/n/b4N+HUpfQ8Mf+ZrAvuG/xayo96HSu53K6B3+Lw+sDDcv7T+zMvZ77T+zMPPrV74vAYwNfwc/wucFbb/G/hF+PwK4N/h87OAF6Pehzjv9xPA6aX0T4uf82L7cx3wHDA6fJ1yn7eOuFVdf2Cxu3/u7ruAF4AREWdKtBHAk+HzJ4FTo4sSP+4+EdhYormsfR0BPOWBj4BGZtYqIUHjrIz9LssI4AV33+nuS4HFBP8mUo67r3X3j8PnW4B5QBvS/DMvZ7/Lkhafefi5bQ1f1ggfDhwFvBy2l/y8i34OXgaONjNLTNr4KWe/y5IWP+cAZtYWOAn4f+FrIwU/bxVuVdcGWFns9SrK/6WX6hx4x8xmmNllYVsLd18bPl8HtIgmWkKUta+Z8HNwVXiq5PFip8PTcr/D0yK9CI5GZMxnXmK/Ic0/8/C02SfAemAcwdHDr919T9il+L59u9/h8k1A04QGjpOS++3uRZ/3neHn/Tczqxm2pc3nDfwduBEoDF83JQU/bxVuEqvB7t4bOAG40syOKL7Qg+PKGTHGTCbtK/AQ0AnoCawF7os0TTUys3rAK8C17r65+LJ0/sxL2e+0/8zdvcDdewJtCY4ados2UWKU3G8zOxi4hWD/+wFNgJuiSxh/ZnYysN7dZ0SdpapUuFXdaqBdsddtw7a05O6rw6/rgdcIftnlFx06D7+ujy5htStrX9P658Dd88Nf9oXAo3x3aiyt9tvMahAUL8+6+6thc9p/5qXtd6Z85gDu/jXwATCA4FRgTrio+L59u9/h8obAl4lNGl/F9ntYeMrc3X0n8B/S7/MeBAw3s2UElzQdBfyDFPy8VbhV3XSgc3hnSi7BRYyjIs5ULcysrpnVL3oOHAfMJdjfC8NuFwIjo0mYEGXt6yjggvAOrMOATcVOr6W8Ete0nEbwuUOw32eFd2DtC3QGpiU6XzyE1688Bsxz9/8rtiitP/Oy9jvdP3Mza25mjcLntYFjCa7v+wA4PexW8vMu+jk4HXg/PAKbUsrY7/nF/nNiBNd5Ff+8U/7n3N1vcfe27t6R4O/0++5+Lqn4eUd9d0Q6PAjuullIcH3Eb6POU437uR/B3WSzgE+L9pXgvP97wCLgXaBJ1FnjtL/PE5wi2k1w7cMlZe0rwR1XD4Y/A3OAvlHnj/N+Px3u12yCX2itivX/bbjfC4ATos5fhf0eTHAadDbwSfg4Md0/83L2O60/c6AHMDPcv7nA78P2/QgK0cXAS0DNsL1W+HpxuHy/qPchzvv9fvh5zwWe4bs7T9Pi57zE92Ao391VmnKft6a8EhEREUkROlUqIiIikiJUuImIiIikCBVuIiIiIilChZuIiIhIilDhJiIiIpIiVLiJZAAz80o8nqimLMvC9XeM0/qeCNd3UTzWVx3M7KIKfs/HR501FkW5o84hkkly9t5FRNLAk6W0tQSOB7bx3STLxU2q1kSZKR8YU87y+YkKIiKpSeO4iWQoMxtKMGr4cg9GE0/UdjsBNYAl7r47DutrRTAdzVp331TV9VWH8Gjgf4AJ7j402jTxU3S0zd0t6iwimUJH3EQkodx9SZzXt5ZgpgcRkbSna9xE5AeKXzdmZj3M7CUzW2dmBWZ2bdinvpldZmavm9liM9tuZlvNbKaZ/TacB7G0dZd6jZuZjQ/bh5pZHzMbZWZfmtkOM5tlZpfsLWuJ9tvC9tvMrIWZPWxmq8xsp5ktNbM/m1mtMtZZw8xuMrN54fbXmdlTZta++Hpj/87GpsTn0DP8Xn9hZt+Y2Qwzu7ic99Yws6vMbKqZbQ7fMy/c76blvK+pmd0Rfo6bzWybmS0Kswws531nmtmU8Gdgi5m9Z2aDy+jb1cyeNLPlZrYr7L/MzF4zsx/H9l0SySw64iYi5RkE/BtYDYwH6gPbw2WHAA8D6wnmrMwjmNfzUOBPwHAzG+LuO2Lc5jDgunCd7wDtgYHA/zOzRu5+X4zrawfMIJhz8X9AA4L5OW8CDgSGF+9sZtkEc3MOA74hmKd0K3BUuJ7RMW4/Hg4FHiL4HMYB+wBDgMfNrJe7X1O8c1iQvk0wJ+N2glPi24HDCfb7LDM7yt0/L/G+XsCbQCtgI8FnvgPoAJwddvtfyXBmdgfB/KWTwvf3IPh+DTazoe4+pVjf7sBkgp+l+cAbBHOltiG45rI28EqM3x+RzBH1ZKl66KFHNA+CP+oOLCtl2RPhMicowrJK6dOW4I9zVon2RgRFgwM3lfK+ZeGyjiXaxxfb5k9LLDsvbN8E1Ckj60Ul2m8rtr5Hgdxiyw4AtoTLBpV437VF3xdg32LtNYHni63zthi+1xeF7xkf42dU/HP4B5BdbNmhwOZw2Ykl3veXsH0e0KZYe22CG1EcmFLiPfWAleGyh4DaJZY3BwaXaCvK9iXQp1h7FvBIuGxcifc8HrbfUsr+1gMGRP1vQw89kvmhU6UiUp75wB/cvbDkAndf5e7vl1zm7l8DRUeATq/ENl9x98dLrPMZgiKkAdA3xvWtBK5x913F1jcPeDp8eXSJ/kXZf+fuS4u9ZydwNcFduJU1ZC/DgVxbxvtWAze6e0GxPFOBv4Uvf1XUHp6i/kXRvrj76mLv+Qa4nOAI4mFmNqjYNi4lKManAFeEfSn23g3uXtadxn9w9xnF+hYCt4YvDzezGsX6tgi/vl1yJe6+1YsdnRORH9KpUhEpz8jixUJJZmYEp1OPIPijX5vglGTRXYZdKrHNsk5Fzic4UtY6xvW9X7IIKbY+iq/PzNoB+wIFwIsl3+DuX5jZOODUGDMU2dtwIJ+V0f5yWDiW9DTwe4JTkjnuvgfoQ3Dkao27jyv5hnAf3iA49TmU4LQlBKeGAR5391iHG/jBZ+bu+Wb2FdCY4BT6unDRNOBE4N9mdiswsYx9E5FSqHATkfIsL2uBmbUAXiW4/qwsDSqxzRVltG8Ov5Z6Q0Gc1tcm/LrWyx6qpMzvSQXMd/eLKvG+pWW0rwAKCfahKUFh2GYv7wEouratTbG2DkUZK5GvvO9xY77/Pf4rwbV2RxNcw7jTzD4BJgDPuPucSmxfJGPoVKmIlKe0I1VF/h9B0TYZOJbggvlcD8b0qlmFbf7gtGwVVWZ95R1xine+6hLrUbNKD+pZ2qn0cvpud/djgMMIrkOcCBwE3AjMNrPfVzaHSCZQ4SYiMTOzugSnuwqAk9393fAaqKKjVPtHl65K1oRfW5e4Lqu4jgnKUpFttif4Pb6D4AYBCK6Hg+CUb1n2K9EXvjtq1rUS+WLm7lPd/XZ3P47gaOHFwB7gNjNLSAaRVKTCTUQqoyHB748t4c0IJZ2b2Djx4e4rCE6FZgM/KbnczJoQHF1MtNPNLLeU9qLv8+Tw+jYIhizZCrQxs5I3XhCO4XZK+HJ8sUVjw68/Da9dTBh33+XuTwAfEVwf2SOR2xdJJSrcRKQy8oGvgEZmdk7xBWZWNA5bqvpn+PVOMyu67ouwcLqf4ML/RGsL/NnMvv2dbWb9+O77/I+i9vBGjH8XtVswJVjRe2oRDPVRD/jI3YtuTIDg1PcagtPf/yw5OLGZNS9rQN1YmNkVpR1RM7P9CE6ZQtWuIxRJa7o5QURi5u4FZnYncC/wrJldRTDuWSegP3AX8JvoElbJP4Djwsc8M3ufYAiQgQR3zT4FXADsKnMNZetmZk+Us3y7u19RSvu/gSuAU8wsj2BMtSEEv8P/5e5vlOh/K8GwKUOBReE+fENwU0ArgtOi3zsq6u5bzGwEwQC6VxIM0juZ7wbg7UUwjl1ZQ4JU1GXAg2b2OTCX4OhgS4JBkXOBF9x9WhW3IZK2VLiJSKW4+31mtgz4NcGRkoMJ/hCf5+7PmllKFm7uvsfMTgGuBy4kODX6NfAuwewAvwu7flGJ1bcI11mWTQQFWklTCQYRvp3vZheYA/wLeKyUfdhhZscRjNl2PnAkUIOguH4a+Iu7f1nK+/LCmQ1+RXA69ViCmzHWAM8RzJRRVb8DTiYYQHggwZ3H+QR3lT6KZk0QKZfFPlyPiEhmMrMcguK0K9C3+KCz1bS9JwgKvYvDa8BEJMPpGjcRkRLCCd1rlGirS3CNW1dgTnUXbSIipdGpUhGRH3oAOMjMZgFrCa4pOwRoRnDa9OLooolIJtMRNxGRH3qE4Lqy/QmmtxpEcBftv4BeOtomIlHRNW4iIiIiKUJH3ERERERShAo3ERERkRShwk1EREQkRahwExEREUkRKtxEREREUsT/B1Rww5MS1oIJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = np.array(score)\n",
    "avg_score = running_mean(score, 50)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.ylabel(\"Episode Duration\",fontsize=22)\n",
    "plt.xlabel(\"Training Epochs\",fontsize=22)\n",
    "plt.plot(avg_score, color='green')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
